\documentclass[uplatex]{jsarticle}
\usepackage{subfiles}
\usepackage{array,booktabs}
\usepackage{float}
\usepackage{amsmath}
\usepackage[dvipdfmx]{graphicx}
\usepackage[dvipdfmx,bookmarks=true]{hyperref}
\usepackage{pxjahyper}
\usepackage{ascmac}
\usepackage{siunitx}
\graphicspath{{images/}{../images/}}


\begin{document}


\title{先端人工知能論最終課題レポート}
\author{下村拓}
\date{2018/08/03}
\maketitle


\section{設定した問題の概要}
日本人、韓国人、中国人などはとても似た顔をしている。
しかし、我々日本人は微妙な違いを見分けかなりの精度でこれらの国を見分けることができる。
このタスクを機械が同様の精度で行うことができれば様々な場所で活躍できると考えられる。
例えば、液晶に映る日本語と外国語の表示切り替えを前に立っている外国人の数等で、
時間配分を変えることが可能であると考えている。
よって、今回は日本人か外国人かの判定をCNNに行わせることとする。


\section{利用した手法の概要と工夫点}
モデルのアーキテクチャとしては基本的にAlexNetのものを用いるところから始めた。
ただし、$50\times50$の画像を入力するため、次元数は異なる。

まずは画像データについて、正規化するために255で割ることで0から1の浮動小数点とした。
また、全ての画素値の平均と分散を求め、

\begin{equation}
  \frac{data - mean}{std}
\end{equation}

とすることで標準化を行った。

次にデータオーギュメンテーションを行った。
画像を水平に移動させるものと、画像を水平に反転させるものの二種類のデータ拡張の手法を用いた。

モデルについては、AlexNetをベースにしたが、
次元が減ることが不利になるのではないかと考え、MaxPooling層を削った。
Max Pooling層の代わりにConvolution層を増やした。
また、学習をしていく上で、常にヴァリデーションデータとトレインデータのロスの差が
大きかったことから、過学習を抑制できていないと考えられたため、
Dropoutの層を増やした。
最後の全結合については、データを単に平滑化すると重みの数が増えるため、
Global Average Polling層を用いて1次元データにした。

今回のデータセットは正解ラベルに偏りが大きいものであったため、
その課題を修正するために工夫が必要だった。
ダウンサンプリングはデータ数が少なかったため適切ではなく、
オーバーサンプリングは顔の特徴量を損なうことなくデータ拡張する手法が見つからなかった。
そのため損失関数に重みをつけることとした。
交差エントロピー誤差を損失関数としていたが、
外国人のラベルで誤った際の損失を6倍とした。
6倍の値はデータ数の偏りに起因する。


\section{利用したデータ}
今回はJリーグ選手の顔を用いた。
理由は、外国人選手が含まれていることと一括で大量のラベル付き顔写真が得られるからである。
Jリーグ公式の選手名鑑から$50\times50$の画像と身長や体重、出身地の情報を取得した。
出身地の情報から日本の都道府県であるかないかで日本人と外国人のラベルをつけた。

データは全部で601件あり、日本人と外国人はそれぞれ516, 85件であった。
日本人の数は外国人のおよそ6倍であり、この値から損失のハイパーパラメータを決定した。


\section{得られた結果と評価}
全データの7割を訓練用に、1割を検証用、2割をテスト用として扱った。
下表は最終的な訓練、検証、テストの精度、ロスを並べたものである。

\begin{table}[H]
  \caption{学習結果}
  \begin{center}
    \begin{tabular}{lc} \hline
      train accuracy & 0.9228 \\
      train loss & 5.3523 \\
      validation accuracy & 0.8871 \\
      validation loss & 8.0523 \\
      test accuracy & 0.9024 \\
      test loss & 12.66 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

テスト画像は123件あり、日本人が103件、外国人が20件存在した。
その中で誤ったテストは12件で日本人が11人、外国人が1人となっている。
上表の環境の下、テストで誤った画像を下に示す。

\begin{figure}[H]
  \begin{center}
    \includegraphics{../data/err_images/0.jpg}
    \includegraphics{../data/err_images/1.jpg}
    \includegraphics{../data/err_images/2.jpg}
    \includegraphics{../data/err_images/3.jpg}
    \includegraphics{../data/err_images/4.jpg}
    \includegraphics{../data/err_images/5.jpg}
    \\
    \includegraphics{../data/err_images/6.jpg}
    \includegraphics{../data/err_images/7.jpg}
    \includegraphics{../data/err_images/8.jpg}
    \includegraphics{../data/err_images/9.jpg}
    \includegraphics{../data/err_images/10.jpg}
    \includegraphics{../data/err_images/11.jpg}
    \caption{テストで誤った画像}
  \end{center}
\end{figure}

また、学習の進捗状況を数に示す。

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=7cm]{../data/history/acc.png}
    \includegraphics[width=7cm]{../data/history/loss.png}
    \caption{学習の進捗}
  \end{center}
\end{figure}

図からは学習がそれほど過学習せずに進んだことがわかる。
これはデータ拡張やDropout層を積んだことの成果であると考えられる。

精度はおよそ9割となっており、
外国人の誤りは1件だけであったことから
損失関数のペナルティに関する重み付けも効果があったと考えられる。

本モデルを向上させるためにさらにできる工夫は
\begin{itemize}
  \item データを増やす
  \item 外国人のデータを拡張する
\end{itemize}

などが考えられる。

気になる点として、
validationの学習曲線がジグザグになってしまっていることがあげられる。
この現象は頑健性が乏しかったことに起因するのかと予想したが、
改善する手法が思いつかなかった。


\end{document}
